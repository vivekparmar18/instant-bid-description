import os
import json
import boto3
from fuzzywuzzy import fuzz
from botocore.config import Config
from langchain_aws import ChatBedrock
from langchain_community.docstore.document import Document
from langchain.chains.question_answering import load_qa_chain
from langchain.text_splitter import RecursiveCharacterTextSplitter
from app.constants import Messages, Prompts


class DescriptionGenerator:

    def __init__(self):
        os.environ['AWS_DEFAULT_REGION'] = "us-east-1"
        self.bedrock_client = boto3.client(service_name='bedrock-runtime', region_name="us-east-1",
                                           config=Config(read_timeout=3600, connect_timeout=3600))

        self.model_id_llm = 'anthropic.claude-3-5-sonnet-20240620-v1:0'

        self.paragraph_anthropic_llm = ChatBedrock(
            model_id=self.model_id_llm,
            model_kwargs={
                "max_tokens": 10000,
                "temperature": 0,
                "top_p": 0.9,
                "top_k": 250,
                "stop_sequences": [],
            },
            client=self.bedrock_client,
        )

        self.matching_threshold = 60
        self.reference_description_first_last_line = [
            "Here's a compact bullet",
            "Here's a comprehensive yet",
            "This overview covers all",
            "Here's a bullet-point summary",
            "This summary covers all",
            "This JSON file describes",
            "Here's a detailed description",
            "This bid is focused",
            "This JSON appears to",
            "Here's an improved and",
            "Here's a refined version"
        ]

    async def __generate_description(self, docs, query, llm):
        qa = load_qa_chain(llm, chain_type="stuff")
        chain_run = qa.invoke({"input_documents": docs, "question": query})
        return chain_run

    async def __data_formatter(self, json_data):
        """ This method is used to format the data and prepare chunks """

        raw_text = json_data
        print(f"Number of tokens: {self.paragraph_anthropic_llm.get_num_tokens(raw_text)}")
        text_splitter = RecursiveCharacterTextSplitter(chunk_size=10000, chunk_overlap=200)
        texts = text_splitter.split_text(raw_text)
        docs = [Document(page_content=t) for t in texts]
        return docs

    async def __first_line_remove(self, line, examples):
        words = line.split()
        start_of_first_line = ' '.join(words[:4])
        return any(
            fuzz.token_sort_ratio(start_of_first_line, example) > self.matching_threshold for example in examples)

    async def __last_line_remove(self, line, examples):
        words = line.split()
        start_of_last_line = ' '.join(words[:4])
        return any(fuzz.token_sort_ratio(start_of_last_line, example) > self.matching_threshold for example in examples)

    async def __post_processing(self, description):
        """ This method is used to post-process the description generated by LLM"""

        text = description.strip()
        lines = text.split('\n')
        if await self.__first_line_remove(lines[0], self.reference_description_first_last_line):
            lines = lines[1:]
        if await self.__last_line_remove(lines[-1], self.reference_description_first_last_line):
            lines = lines[:-1]

        modified_text = '\n'.join(lines)
        return modified_text

    async def __pre_processing(self, api_response):
        """ This method is used to pre-process the description generated by LLM"""

        json_data = json.dumps(api_response)

        if not json_data:
            return Messages.BLANK_PDF

        docs = await self.__data_formatter(json_data)

        return docs

    async def get_paragraph_description(self, api_response, num_chars):
        """ This method is used to get the description of document """

        docs = await self.__pre_processing(api_response)

        if isinstance(docs, str):
            return docs

        query = Prompts.PARAGRAPH_PROMPT.format(num_chars=num_chars)

        description = await self.__generate_description(docs, query, self.paragraph_anthropic_llm)
        description = description['output_text']

        docs = await self.__data_formatter(description)
        description = await self.__generate_description(docs, Prompts.IMPROVE_PROMPT, self.paragraph_anthropic_llm)
        description = description['output_text']

        description = await self.__post_processing(description)
        return description
